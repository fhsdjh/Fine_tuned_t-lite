{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11282155,"sourceType":"datasetVersion","datasetId":7053755},{"sourceId":11282555,"sourceType":"datasetVersion","datasetId":7054037}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:52:06.046216Z","iopub.execute_input":"2025-04-05T06:52:06.046551Z","iopub.status.idle":"2025-04-05T06:52:13.525275Z","shell.execute_reply.started":"2025-04-05T06:52:06.046521Z","shell.execute_reply":"2025-04-05T06:52:13.524194Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.4-py3-none-manylinux_2_24_x86_64.whl (76.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.4\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\nimport torch\nfrom datasets import load_dataset\n\n\ndataset = load_dataset(\"json\", data_files=\"/kaggle/input/kjlkjkj/asd1.jsonl\")\n\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:52:27.889787Z","iopub.execute_input":"2025-04-05T06:52:27.890124Z","iopub.status.idle":"2025-04-05T06:52:50.564009Z","shell.execute_reply.started":"2025-04-05T06:52:27.890095Z","shell.execute_reply":"2025-04-05T06:52:50.563149Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77d73e1c52294e5ab6309d7080df594e"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'answer'],\n        num_rows: 1097\n    })\n})\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling\n)\nfrom peft import (\n    prepare_model_for_kbit_training,\n    get_peft_model,\n    LoraConfig,\n    PeftModel\n)\nfrom datasets import load_dataset\n\n\nmodel_name = \"t-tech/T-lite-it-1.0\"\n\nnf4_config = BitsAndBytesConfig(\n   load_in_4bit=True,\n   bnb_4bit_quant_type=\"nf4\",\n   bnb_4bit_use_double_quant=True,\n   bnb_4bit_compute_dtype=torch.bfloat16\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map='auto',\n    quantization_config=nf4_config,\n    use_cache=False\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:52:50.565136Z","iopub.execute_input":"2025-04-05T06:52:50.565672Z","iopub.status.idle":"2025-04-05T06:54:38.600449Z","shell.execute_reply.started":"2025-04-05T06:52:50.565648Z","shell.execute_reply":"2025-04-05T06:54:38.599748Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e150952e9110473ca83ef2c87568b9e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ddbe7a87bdb4d8e972d0b516796836c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40a22cf9d8d04a49931029fe3af0b5cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"075d11c319da4cbc927696ac6fb14127"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91cd3e5ffa064066b008161399e9272a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e13ed1c891b4fc49e5db52512fa2a0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01515afde12f44658ad4e8f8e50b06a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168dc9f33c9f416ea916708ad1271393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14e82927bcc449159f8dc81222891602"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc2f059189348dfae30bf917ee9ad76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb65384d4ff42c795ac30156130808b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4486c174023742dca779648d4d5d4800"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d58dd1eac25e4241927f18821db08f4e"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, peft_config)\ntok = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:38.601770Z","iopub.execute_input":"2025-04-05T06:54:38.601983Z","iopub.status.idle":"2025-04-05T06:54:39.431296Z","shell.execute_reply.started":"2025-04-05T06:54:38.601965Z","shell.execute_reply":"2025-04-05T06:54:39.430544Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def a(q):\n    messages = [\n    {\"role\": \"user\", \"content\": q}]\n    text = tok.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True\n    )\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:39.432485Z","iopub.execute_input":"2025-04-05T06:54:39.432761Z","iopub.status.idle":"2025-04-05T06:54:39.436777Z","shell.execute_reply.started":"2025-04-05T06:54:39.432729Z","shell.execute_reply":"2025-04-05T06:54:39.435907Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(\n        [a(q) for q in examples[\"question\"]],\n        text_target=examples[\"answer\"],\n        padding=\"max_length\",\n        padding_side='left',\n        truncation=True,\n        max_length=64\n    )\n\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\ntokenized_dataset = tokenized_dataset.remove_columns([\"question\", \"answer\"])\nprint(tokenized_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:39.437547Z","iopub.execute_input":"2025-04-05T06:54:39.437757Z","iopub.status.idle":"2025-04-05T06:54:39.876799Z","shell.execute_reply.started":"2025-04-05T06:54:39.437731Z","shell.execute_reply":"2025-04-05T06:54:39.875864Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1097 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4d30954dc064e83afd042f85d1b8cb0"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 1097\n    })\n})\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=4,\n    num_train_epochs=3,\n    learning_rate=2e-5,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_strategy=\"steps\",\n    save_steps=500,\n    report_to=\"none\",\n    fp16=True,\n    gradient_checkpointing=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:39.877658Z","iopub.execute_input":"2025-04-05T06:54:39.877920Z","iopub.status.idle":"2025-04-05T06:54:39.910237Z","shell.execute_reply.started":"2025-04-05T06:54:39.877899Z","shell.execute_reply":"2025-04-05T06:54:39.909333Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:39.911003Z","iopub.execute_input":"2025-04-05T06:54:39.911235Z","iopub.status.idle":"2025-04-05T06:54:39.933196Z","shell.execute_reply.started":"2025-04-05T06:54:39.911215Z","shell.execute_reply":"2025-04-05T06:54:39.932476Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T06:54:39.934757Z","iopub.execute_input":"2025-04-05T06:54:39.934976Z","iopub.status.idle":"2025-04-05T07:28:11.296465Z","shell.execute_reply.started":"2025-04-05T06:54:39.934956Z","shell.execute_reply":"2025-04-05T07:28:11.295731Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [204/204 33:20, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>55.142100</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>44.821100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>33.227600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>29.486700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>30.733600</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>28.233800</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>27.579200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>26.163300</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>24.319200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>23.197600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>22.267900</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>21.551400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>19.930100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>20.377800</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>19.094500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>17.945800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>17.668300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>17.341300</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>17.424800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>16.282700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=204, training_loss=25.46945930929745, metrics={'train_runtime': 2010.9839, 'train_samples_per_second': 1.637, 'train_steps_per_second': 0.101, 'total_flos': 8888408909807616.0, 'train_loss': 25.46945930929745, 'epoch': 2.9890909090909092})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_model\")\ntokenizer.save_pretrained(\"./fine_tuned_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:28:11.297609Z","iopub.execute_input":"2025-04-05T07:28:11.298049Z","iopub.status.idle":"2025-04-05T07:28:12.032522Z","shell.execute_reply.started":"2025-04-05T07:28:11.298019Z","shell.execute_reply":"2025-04-05T07:28:12.031826Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_model/tokenizer_config.json',\n './fine_tuned_model/special_tokens_map.json',\n './fine_tuned_model/vocab.json',\n './fine_tuned_model/merges.txt',\n './fine_tuned_model/added_tokens.json',\n './fine_tuned_model/tokenizer.json')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel    \nfrom transformers import AutoModelForCausalLM, StoppingCriteria, AutoTokenizer, StoppingCriteriaList, TextIteratorStreamer\n\nmodel_name = \"t-tech/T-lite-it-1.0\"\nadapters_name = \"/kaggle/input/dfdffd/asd1\"\n\nprint(f\"Starting to load the model {model_name} into memory\")\n\nm = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.bfloat16,\n    device_map={\"\": 0}\n)\nm = PeftModel.from_pretrained(m, adapters_name)\nm = m.merge_and_unload()\ntok = AutoTokenizer.from_pretrained(model_name)\n\nprint(f\"Successfully loaded the model {model_name} into memory\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T07:42:55.369875Z","iopub.execute_input":"2025-04-05T07:42:55.370327Z","iopub.status.idle":"2025-04-05T07:45:44.024389Z","shell.execute_reply.started":"2025-04-05T07:42:55.370288Z","shell.execute_reply":"2025-04-05T07:45:44.023605Z"}},"outputs":[{"name":"stdout","text":"Starting to load the model t-tech/T-lite-it-1.0 into memory\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/712 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"305cb1a05ed8473d824a53e49aeb7362"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"099995e949c0423f9f7a23f4110d3887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef5cc941c7b4902b2920b5e7be8da0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd41e903de4b450a9ca427dd0176b097"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc5496a6574493caf958274ea13713d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b64ad8ff32b34735b2e31f2f68963adf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acb951c841d347718f6736ccf6c4fd55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43e5897f683f40ef842db17548afca37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0197c1d0f69d4ca5ae9cdfefcebb2502"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.90k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e2336a13a1444c6b5c682e3e5f13eb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204fd3ca4b284e1f8cf1259fab299b8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f094d0a5253f494e8ad8ee232e2cd6cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d239aaf728f4b07860fe15e3d1d1d20"}},"metadata":{}},{"name":"stdout","text":"Successfully loaded the model t-tech/T-lite-it-1.0 into memory\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"prompt = \"Как звали лучшего друга Пятачка?\"\nmessages = [\n    {\"role\": \"user\", \"content\": prompt}\n]\ntext = tok.apply_chat_template(\n    messages,\n    tokenize=False,\n    add_generation_prompt=True\n)\nmodel_inputs = tok([text], return_tensors=\"pt\").to(m.device)\n\ngenerated_ids = m.generate(\n    **model_inputs,\n    max_new_tokens=512\n)\ngenerated_ids = [\n    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n]\n\nresponse = tok.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\nprint(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T08:38:44.402009Z","iopub.execute_input":"2025-04-05T08:38:44.402300Z","iopub.status.idle":"2025-04-05T08:38:50.893465Z","shell.execute_reply.started":"2025-04-05T08:38:44.402279Z","shell.execute_reply":"2025-04-05T08:38:50.892562Z"}},"outputs":[{"name":"stdout","text":"Лучшего друга Пятачка в мультфильме «Винни-Пух» зовут Кристофер Робин. Однако, если вы имеете в виду другого персонажа из мира Винни-Пуха, например, из книг А.А. Милна, то его другом является Тигруля (Тигра). Если речь идет о каком-то конкретном произведении или адаптации, уточните, пожалуйста.\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}